# DÃ©tection d'Anomalies et Analyse des Journaux de RequÃªte

## ðŸ“ Description du Projet
Ce projet vise Ã  analyser des journaux de requÃªte (logs) afin de dÃ©tecter des anomalies, classifier les erreurs, et regrouper les Ã©vÃ©nements similaires Ã  l'aide de techniques de Machine Learning et d'analyse de donnÃ©es. Les logs, gÃ©nÃ©rÃ©s par des systÃ¨mes, contiennent des informations prÃ©cieuses pour la surveillance, le diagnostic et l'optimisation des performances.

## Objectifs Principaux
DÃ©tection d'Anomalies : Identifier des comportements inhabituels dans les logs, tels que des pics de requÃªtes anormaux ou des erreurs inattendues.

Classification des Erreurs : Distinguer les logs normaux des logs d'erreur Ã  l'aide de modÃ¨les de classification supervisÃ©e.

Clustering des Ã‰vÃ©nements : Regrouper les logs similaires pour dÃ©couvrir des motifs rÃ©currents et mieux comprendre les tendances.

Visualisation des RÃ©sultats : Fournir des graphiques et des rapports clairs pour faciliter l'interprÃ©tation des rÃ©sultats.
## Dataset

| Date                             | Hostname  | Process         | IdProcess | Message                                           |
|----------------------------------|-----------|-----------------|-----------|---------------------------------------------------|
| 2024-12-11T17:14:51.738480+01:00 | hilbert02 | gnome-shell     | 2026.0    | meta_window_set_stack_position_no_sync: assert... |
| 2024-12-11T17:20:14.050043+01:00 | hilbert02 | gnome-text-edit | 6677.0    | Trying to snapshot GtkGizmo 0x559f9a9e7800 wit... |
## ðŸ›ï¸ Architecture
Les principales Ã©tapes de l'analyse sont les suivantes :

1. **PrÃ©paration des DonnÃ©es** : Chargement et nettoyage des donnÃ©es issues des journaux de requÃªtes.
2. **Analyse Exploratoire** : Analyse des occurrences des processus, des erreurs et de leur rÃ©partition temporelle.
3. **DÃ©tection des Anomalies** :
   - Identification des pics de logs inhabituels
   - Utilisation de l'algorithme Isolation Forest
4. **Classification** : ModÃ©lisation supervisÃ©e pour distinguer les erreurs des logs normaux (Random Forest).
5. **Clustering** : Regroupement des logs similaires avec K-Means.
6. **Visualisation & GÃ©nÃ©ration de Rapports** : Statistiques et graphiques.

   
|DonnÃ©es Brutes| ----> |PrÃ©paration des DonnÃ©es| ----> | Analyse Exploratoire |
                                                                 |
                                                                 v
| DÃ©tection des  Anomalies | <---- | Classification | <---- | Clustering |
                                                                 |
                                                                 v
                                                          |Visualisation|
## âš™ï¸ PrÃ©requis
Assurez-vous d'avoir les Ã©lÃ©ments suivants :
- Python 3.7 ou supÃ©rieur
- Librairies Python :
  - pandas
  - numpy
  - matplotlib
  - seaborn
  - scikit-learn
  - jupyter 

# ðŸ“ˆ RÃ©sultats et Visualisation
## 1-DÃ©tection d'Anomalies
AprÃ¨s applicationde la mÃ©thode **Isolation Forest**, il a Ã©tÃ© obtenu **1848 anomalies** et le graphique d'evaluation des nombres logs montre une Ã©volution des logs par heure avec une dÃ©tection d'anomalies marquÃ©es par des points rouges, principalement corrÃ©lÃ©es Ã  des pics massifs d'activitÃ©. Ces pics, particuliÃ¨rement concentrÃ©s autour de la mi-dÃ©cembre 2024, dÃ©passent les **20 000** logs par heure, ce qui constitue une dÃ©viation majeure par rapport aux volumes standards. Une hausse moins prononcÃ©e est Ã©galement visible dÃ©but janvier 2025. La concentration des anomalies sur ces pÃ©riodes suggÃ¨re des incidents critiques tels que des pannes systÃ¨me, des surcharges liÃ©es Ã  une maintenance, voire des attaques potentielles (type Denial of Service).
![image](https://github.com/user-attachments/assets/4a64bc8f-15a7-40b8-ab5b-85e3ae8369b6)

## 2-Classification des Erreurs
Le modÃ¨le de classification obtenue affiche une accuracy de 99,99 %, ce qui signifie qu'il classe correctement presque toutes les instances du jeu de donnÃ©es. Le rapport de classification montre une prÃ©cision et un rappel de 1,00 pour la classe majoritaire (0), indiquant une performance parfaite. Pour la classe minoritaire (1), la prÃ©cision est Ã©galement de 1,00, mais le rappel est lÃ©gÃ¨rement infÃ©rieur Ã  0,99, ce qui signifie que 1 % des anomalies n'ont pas Ã©tÃ© dÃ©tectÃ©es. Les moyennes macro et pondÃ©rÃ©e des mÃ©triques (prÃ©cision, rappel, F1-Score) sont toutes de 1,00, confirmant une performance Ã©quilibrÃ©e et excellente. Cependant, il est important de vÃ©rifier si le modÃ¨le gÃ©nÃ©ralise bien sur de nouvelles donnÃ©es et de s'assurer que le dÃ©sÃ©quilibre entre les classes n'affecte pas sa robustesse.
![image](https://github.com/user-attachments/assets/f9fa9662-78d8-42e5-ad0c-6f3dfef6cc93)

## 3-Clustering des Ã‰vÃ©nements
On observe une bonne sÃ©paration entre les groupes, ce qui indique une diffÃ©renciation nette des logs selon les processus et les hÃ´tes associÃ©s. Les clusters semblent rÃ©partis selon des plages spÃ©cifiques de processus, suggÃ©rant des comportements homogÃ¨nes pour certains processus ou groupes de machines.
Le cluster 1 (vert) prÃ©sente une dispersion plus large sur les hÃ´tes, tandis que les clusters 0 (bleu) et 2 (orange) sont concentrÃ©s autour de certaines plages de processus.
![image](https://github.com/user-attachments/assets/eb557155-03ae-4760-a7f7-82041a89a9e3)
## Visualisation 
![image](https://github.com/user-attachments/assets/26a5f2aa-f918-466b-9adc-264a40bce4df)
![image](https://github.com/user-attachments/assets/bc19211f-90bf-4a34-bf97-b42fae999e1b)

# Technologies UtilisÃ©es
**Python** : Langage principal pour le traitement des donnÃ©es et l'implÃ©mentation des modÃ¨les.

**Pandas et NumPy** : Pour la manipulation et l'analyse des donnÃ©es.

**Scikit-learn** : Pour les algorithmes de Machine Learning (classification, clustering, dÃ©tection d'anomalies).

**Matplotlib et Seaborn** : Pour la visualisation des donnÃ©es.

**Jupyter Notebook** : Pour l'exploration interactive des donnÃ©es et la documentation des analyses.

