# D√©tection d'Anomalies et Analyse des Journaux de Requ√™te

## üìù Description du Projet
Ce projet vise √† analyser des journaux de requ√™te (logs) afin de d√©tecter des anomalies, classifier les erreurs, et regrouper les √©v√©nements similaires √† l'aide de techniques de Machine Learning et d'analyse de donn√©es. Les logs, g√©n√©r√©s par des syst√®mes, contiennent des informations pr√©cieuses pour la surveillance, le diagnostic et l'optimisation des performances.

## Objectifs Principaux
D√©tection d'Anomalies : Identifier des comportements inhabituels dans les logs, tels que des pics de requ√™tes anormaux ou des erreurs inattendues.

Classification des Erreurs : Distinguer les logs normaux des logs d'erreur √† l'aide de mod√®les de classification supervis√©e.

Clustering des √âv√©nements : Regrouper les logs similaires pour d√©couvrir des motifs r√©currents et mieux comprendre les tendances.

Visualisation des R√©sultats : Fournir des graphiques et des rapports clairs pour faciliter l'interpr√©tation des r√©sultats.
## Dataset

| Date                             | Hostname  | Process         | IdProcess | Message                                           |
|----------------------------------|-----------|-----------------|-----------|---------------------------------------------------|
| 2024-12-11T17:14:51.738480+01:00 | hilbert02 | gnome-shell     | 2026.0    | meta_window_set_stack_position_no_sync: assert... |
| 2024-12-11T17:20:14.050043+01:00 | hilbert02 | gnome-text-edit | 6677.0    | Trying to snapshot GtkGizmo 0x559f9a9e7800 wit... |
## üèõÔ∏è Architecture
Les principales √©tapes de l'analyse sont les suivantes :

1. **Pr√©paration des Donn√©es** : Chargement et nettoyage des donn√©es issues des journaux de requ√™tes.
2. **Analyse Exploratoire** : Analyse des occurrences des processus, des erreurs et de leur r√©partition temporelle.
3. **D√©tection des Anomalies** :
   - Identification des pics de logs inhabituels
   - Utilisation de l'algorithme Isolation Forest
4. **Classification** : Mod√©lisation supervis√©e pour distinguer les erreurs des logs normaux (Random Forest).
5. **Clustering** : Regroupement des logs similaires avec K-Means.
6. **Visualisation & G√©n√©ration de Rapports** : Statistiques et graphiques.
+-------------------+       +-------------------+       +-------------------+
|  Donn√©es Brutes   | ----> |  Pr√©paration des  | ----> |  Analyse          |
|                   |       |  Donn√©es          |       |  Exploratoire     |
+-------------------+       +-------------------+       +-------------------+
                                                                 |
                                                                 v
+-------------------+       +-------------------+       +-------------------+
|  D√©tection des    | <---- |  Classification   | <---- |  Clustering       |
|  Anomalies        |       |                   |       |                   |
+-------------------+       +-------------------+       +-------------------+
                                                                 |
                                                                 v
+-------------------+
|  Visualisation &  |
|  Rapports         |
+-------------------+
## ‚öôÔ∏è Pr√©requis
Assurez-vous d'avoir les √©l√©ments suivants :
- Python 3.7 ou sup√©rieur
- Librairies Python :
  - pandas
  - numpy
  - matplotlib
  - seaborn
  - scikit-learn
  - jupyter 

# üìà R√©sultats et Visualisation
## 1-D√©tection d'Anomalies
Apr√®s applicationde la m√©thode **Isolation Forest**, il a √©t√© obtenu **1848 anomalies** et le graphique d'evaluation des nombres logs montre une √©volution des logs par heure avec une d√©tection d'anomalies marqu√©es par des points rouges, principalement corr√©l√©es √† des pics massifs d'activit√©. Ces pics, particuli√®rement concentr√©s autour de la mi-d√©cembre 2024, d√©passent les **20 000** logs par heure, ce qui constitue une d√©viation majeure par rapport aux volumes standards. Une hausse moins prononc√©e est √©galement visible d√©but janvier 2025. La concentration des anomalies sur ces p√©riodes sugg√®re des incidents critiques tels que des pannes syst√®me, des surcharges li√©es √† une maintenance, voire des attaques potentielles (type Denial of Service).
![image](https://github.com/user-attachments/assets/4a64bc8f-15a7-40b8-ab5b-85e3ae8369b6)

## 2-Classification des Erreurs
Le mod√®le de classification obtenue affiche une accuracy de 99,99 %, ce qui signifie qu'il classe correctement presque toutes les instances du jeu de donn√©es. Le rapport de classification montre une pr√©cision et un rappel de 1,00 pour la classe majoritaire (0), indiquant une performance parfaite. Pour la classe minoritaire (1), la pr√©cision est √©galement de 1,00, mais le rappel est l√©g√®rement inf√©rieur √† 0,99, ce qui signifie que 1 % des anomalies n'ont pas √©t√© d√©tect√©es. Les moyennes macro et pond√©r√©e des m√©triques (pr√©cision, rappel, F1-Score) sont toutes de 1,00, confirmant une performance √©quilibr√©e et excellente. Cependant, il est important de v√©rifier si le mod√®le g√©n√©ralise bien sur de nouvelles donn√©es et de s'assurer que le d√©s√©quilibre entre les classes n'affecte pas sa robustesse.
![image](https://github.com/user-attachments/assets/f9fa9662-78d8-42e5-ad0c-6f3dfef6cc93)

## 3-Clustering des √âv√©nements
On observe une bonne s√©paration entre les groupes, ce qui indique une diff√©renciation nette des logs selon les processus et les h√¥tes associ√©s. Les clusters semblent r√©partis selon des plages sp√©cifiques de processus, sugg√©rant des comportements homog√®nes pour certains processus ou groupes de machines.
Le cluster 1 (vert) pr√©sente une dispersion plus large sur les h√¥tes, tandis que les clusters 0 (bleu) et 2 (orange) sont concentr√©s autour de certaines plages de processus.
![image](https://github.com/user-attachments/assets/eb557155-03ae-4760-a7f7-82041a89a9e3)
## Visualisation 
![image](https://github.com/user-attachments/assets/26a5f2aa-f918-466b-9adc-264a40bce4df)
![image](https://github.com/user-attachments/assets/bc19211f-90bf-4a34-bf97-b42fae999e1b)

# Technologies Utilis√©es
**Python** : Langage principal pour le traitement des donn√©es et l'impl√©mentation des mod√®les.

**Pandas et NumPy** : Pour la manipulation et l'analyse des donn√©es.

**Scikit-learn** : Pour les algorithmes de Machine Learning (classification, clustering, d√©tection d'anomalies).

**Matplotlib et Seaborn** : Pour la visualisation des donn√©es.

**Jupyter Notebook** : Pour l'exploration interactive des donn√©es et la documentation des analyses.

